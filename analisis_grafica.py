import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, validation_curve, learning_curve
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de gr√°ficas
plt.style.use('default')
sns.set_palette("husl")

print("="*80)
print("üìä AN√ÅLISIS COMPLETO: BIAS, VARIANZA Y AJUSTE DEL MODELO KNN")
print("="*80)

# ======================
# 1. CARGA Y PREPARACI√ìN DE DATOS
# ======================

print("\n1Ô∏è‚É£ CARGA Y PREPARACI√ìN DE DATOS")
print("-" * 50)

# Cargar dataset
df = pd.read_csv("2016-2024_liga_mx.csv")
df_clean = df[['home_goals_half_time', 'away_goals_half_time', 'season', 'home_win', 'home_team', 'away_team']].dropna()
df_clean["home_win_binary"] = df_clean["home_win"].apply(lambda x: 1 if x == True or x == "True" else 0)

print(f"üìà Dataset original: {len(df)} registros")
print(f"üìä Dataset limpio: {len(df_clean)} registros")
print(f"üéØ Clases balanceadas: {df_clean['home_win_binary'].value_counts().to_dict()}")

# Preparar caracter√≠sticas
X = df_clean[['home_goals_half_time', 'away_goals_half_time', 'season']].values
y = df_clean['home_win_binary'].values

# ======================
# 2. SEPARACI√ìN TRAIN/VALIDATION/TEST
# ======================

print("\n2Ô∏è‚É£ SEPARACI√ìN DE DATOS: TRAIN/VALIDATION/TEST")
print("-" * 50)

# Primera divisi√≥n: Train+Validation (80%) vs Test (20%)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Segunda divisi√≥n: Train (60%) vs Validation (20%)
X_train, X_validation, y_train, y_validation = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 de 80% = 20% total
)

print(f"üîπ Conjunto de Entrenamiento: {len(X_train)} muestras ({len(X_train)/len(X)*100:.1f}%)")
print(f"üîπ Conjunto de Validaci√≥n: {len(X_validation)} muestras ({len(X_validation)/len(X)*100:.1f}%)")
print(f"üîπ Conjunto de Prueba: {len(X_test)} muestras ({len(X_test)/len(X)*100:.1f}%)")

# Verificar distribuci√≥n de clases
print(f"\nüìä DISTRIBUCI√ìN DE CLASES:")
print(f"Train - Victoria Local: {np.sum(y_train)}/{len(y_train)} ({np.sum(y_train)/len(y_train)*100:.1f}%)")
print(f"Validation - Victoria Local: {np.sum(y_validation)}/{len(y_validation)} ({np.sum(y_validation)/len(y_validation)*100:.1f}%)")
print(f"Test - Victoria Local: {np.sum(y_test)}/{len(y_test)} ({np.sum(y_test)/len(y_test)*100:.1f}%)")

# Normalizaci√≥n
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_validation_scaled = scaler.transform(X_validation)
X_test_scaled = scaler.transform(X_test)

# ======================
# 3. AN√ÅLISIS DE CURVAS DE VALIDACI√ìN
# ======================

print("\n3Ô∏è‚É£ AN√ÅLISIS DE CURVAS DE VALIDACI√ìN")
print("-" * 50)

# Rango de valores k para analizar
k_range = np.arange(1, 51, 2)  # k = 1, 3, 5, ..., 49

# Calcular curvas de validaci√≥n
train_scores, validation_scores = validation_curve(
    KNeighborsClassifier(), X_train_scaled, y_train,
    param_name='n_neighbors', param_range=k_range,
    cv=5, scoring='accuracy', n_jobs=-1
)

# Calcular medias y desviaciones est√°ndar
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
validation_mean = np.mean(validation_scores, axis=1)
validation_std = np.std(validation_scores, axis=1)

# Encontrar mejor k
best_k_idx = np.argmax(validation_mean)
best_k = k_range[best_k_idx]
best_validation_score = validation_mean[best_k_idx]

print(f"üéØ Mejor k encontrado: {best_k}")
print(f"üìà Mejor score de validaci√≥n: {best_validation_score:.4f} ¬± {validation_std[best_k_idx]:.4f}")

# ======================
# 4. AN√ÅLISIS DE CURVAS DE APRENDIZAJE
# ======================

print("\n4Ô∏è‚É£ AN√ÅLISIS DE CURVAS DE APRENDIZAJE")
print("-" * 50)

# Calcular curvas de aprendizaje con el mejor k
train_sizes = np.linspace(0.1, 1.0, 10)
train_sizes_abs, train_scores_lc, validation_scores_lc = learning_curve(
    KNeighborsClassifier(n_neighbors=best_k), X_train_scaled, y_train,
    train_sizes=train_sizes, cv=5, scoring='accuracy', n_jobs=-1
)

# Calcular medias y desviaciones
train_mean_lc = np.mean(train_scores_lc, axis=1)
train_std_lc = np.std(train_scores_lc, axis=1)
validation_mean_lc = np.mean(validation_scores_lc, axis=1)
validation_std_lc = np.std(validation_scores_lc, axis=1)

# ======================
# 5. EVALUACI√ìN FINAL EN CONJUNTO DE PRUEBA
# ======================

print("\n5Ô∏è‚É£ EVALUACI√ìN FINAL EN CONJUNTO DE PRUEBA")
print("-" * 50)

# Entrenar modelo final con mejores par√°metros
final_model = KNeighborsClassifier(n_neighbors=best_k)
final_model.fit(X_train_scaled, y_train)

# Evaluaciones en los tres conjuntos
train_accuracy = final_model.score(X_train_scaled, y_train)
validation_accuracy = final_model.score(X_validation_scaled, y_validation)
test_accuracy = final_model.score(X_test_scaled, y_test)

print(f"üìä RESULTADOS FINALES:")
print(f"üîπ Accuracy en Entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
print(f"üîπ Accuracy en Validaci√≥n: {validation_accuracy:.4f} ({validation_accuracy*100:.2f}%)")
print(f"üîπ Accuracy en Prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")

# Predicciones para an√°lisis detallado
y_pred_test = final_model.predict(X_test_scaled)

# ======================
# 6. DIAGN√ìSTICO DE BIAS, VARIANZA Y AJUSTE
# ======================

print("\n6Ô∏è‚É£ DIAGN√ìSTICO DE BIAS, VARIANZA Y AJUSTE")
print("-" * 50)

# Calcular diferencias para diagn√≥stico
train_val_gap = train_accuracy - validation_accuracy
val_test_gap = validation_accuracy - test_accuracy

print(f"üìä M√âTRICAS DE DIAGN√ìSTICO:")
print(f"üîπ Gap Entrenamiento-Validaci√≥n: {train_val_gap:.4f} ({train_val_gap*100:.2f}%)")
print(f"üîπ Gap Validaci√≥n-Prueba: {val_test_gap:.4f} ({val_test_gap*100:.2f}%)")

# Diagn√≥stico de BIAS
if validation_accuracy < 0.65:
    bias_level = "ALTO"
    bias_explanation = "El modelo tiene dificultades para capturar patrones, incluso en validaci√≥n"
elif validation_accuracy < 0.75:
    bias_level = "MEDIO"
    bias_explanation = "El modelo captura patrones b√°sicos pero podr√≠a mejorar"
else:
    bias_level = "BAJO"
    bias_explanation = "El modelo captura bien los patrones subyacentes de los datos"

# Diagn√≥stico de VARIANZA
if train_val_gap > 0.15:
    variance_level = "ALTA"
    variance_explanation = "Gran diferencia entre entrenamiento y validaci√≥n indica alta varianza"
elif train_val_gap > 0.05:
    variance_level = "MEDIA"
    variance_explanation = "Diferencia moderada entre entrenamiento y validaci√≥n"
else:
    variance_level = "BAJA"
    variance_explanation = "Poca diferencia entre entrenamiento y validaci√≥n indica baja varianza"

# Diagn√≥stico de AJUSTE
if train_val_gap > 0.15 and validation_accuracy > 0.70:
    fit_level = "OVERFITTING"
    fit_explanation = "Modelo memoriza entrenamiento pero generaliza mal"
elif validation_accuracy < 0.65:
    fit_level = "UNDERFITTING"
    fit_explanation = "Modelo demasiado simple para capturar patrones complejos"
else:
    fit_level = "GOOD FIT"
    fit_explanation = "Modelo balanceado entre complejidad y generalizaci√≥n"

print(f"\nüîç DIAGN√ìSTICOS:")
print(f"üìà BIAS (Sesgo): {bias_level}")
print(f"   ‚îî‚îÄ‚îÄ {bias_explanation}")
print(f"üìâ VARIANZA: {variance_level}")
print(f"   ‚îî‚îÄ‚îÄ {variance_explanation}")
print(f"‚öñÔ∏è AJUSTE: {fit_level}")
print(f"   ‚îî‚îÄ‚îÄ {fit_explanation}")

# ======================
# 7. AN√ÅLISIS DE VARIANZA POR CROSS-VALIDATION
# ======================

print("\n7Ô∏è‚É£ AN√ÅLISIS DE VARIANZA POR CROSS-VALIDATION")
print("-" * 50)

# Cross-validation con diferentes k
k_values_cv = [1, 3, 5, 7, 11, 15, 21, 31]
cv_results = {}

for k in k_values_cv:
    cv_scores = cross_val_score(
        KNeighborsClassifier(n_neighbors=k), 
        X_train_scaled, y_train, cv=10, scoring='accuracy'
    )
    cv_results[k] = {
        'mean': cv_scores.mean(),
        'std': cv_scores.std(),
        'scores': cv_scores
    }
    print(f"k={k:2d}: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f} (variabilidad: {cv_scores.std()/cv_scores.mean()*100:.1f}%)")

# ======================
# 8. GENERACI√ìN DE GR√ÅFICAS
# ======================

print("\n8Ô∏è‚É£ GENERANDO GR√ÅFICAS COMPARATIVAS")
print("-" * 50)

# Crear figura con subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle('An√°lisis Completo del Modelo KNN: Bias, Varianza y Ajuste', fontsize=16, fontweight='bold')

# Gr√°fica 1: Curva de Validaci√≥n
ax1 = axes[0, 0]
ax1.plot(k_range, train_mean, 'o-', color='blue', label='Entrenamiento', alpha=0.8)
ax1.fill_between(k_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')
ax1.plot(k_range, validation_mean, 'o-', color='red', label='Validaci√≥n', alpha=0.8)
ax1.fill_between(k_range, validation_mean - validation_std, validation_mean + validation_std, alpha=0.2, color='red')
ax1.axvline(x=best_k, color='green', linestyle='--', label=f'Mejor k={best_k}')
ax1.set_xlabel('N√∫mero de Vecinos (k)')
ax1.set_ylabel('Accuracy')
ax1.set_title('Curva de Validaci√≥n\n(An√°lisis de Complejidad)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Gr√°fica 2: Curva de Aprendizaje
ax2 = axes[0, 1]
ax2.plot(train_sizes_abs, train_mean_lc, 'o-', color='blue', label='Entrenamiento', alpha=0.8)
ax2.fill_between(train_sizes_abs, train_mean_lc - train_std_lc, train_mean_lc + train_std_lc, alpha=0.2, color='blue')
ax2.plot(train_sizes_abs, validation_mean_lc, 'o-', color='red', label='Validaci√≥n', alpha=0.8)
ax2.fill_between(train_sizes_abs, validation_mean_lc - validation_std_lc, validation_mean_lc + validation_std_lc, alpha=0.2, color='red')
ax2.set_xlabel('Tama√±o del Conjunto de Entrenamiento')
ax2.set_ylabel('Accuracy')
ax2.set_title('Curva de Aprendizaje\n(An√°lisis de Datos)')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Gr√°fica 3: Comparaci√≥n Train/Val/Test
ax3 = axes[0, 2]
accuracies = [train_accuracy, validation_accuracy, test_accuracy]
labels = ['Entrenamiento', 'Validaci√≥n', 'Prueba']
colors = ['blue', 'orange', 'green']
bars = ax3.bar(labels, accuracies, color=colors, alpha=0.7)
ax3.set_ylabel('Accuracy')
ax3.set_title('Comparaci√≥n de Accuracy\n(Train/Val/Test)')
ax3.set_ylim(0, 1)
for bar, acc in zip(bars, accuracies):
    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
ax3.grid(True, alpha=0.3, axis='y')

# Gr√°fica 4: Matriz de Confusi√≥n
ax4 = axes[1, 0]
cm = confusion_matrix(y_test, y_pred_test)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,
            xticklabels=['No Victoria', 'Victoria'], 
            yticklabels=['No Victoria', 'Victoria'])
ax4.set_title('Matriz de Confusi√≥n\n(Conjunto de Prueba)')
ax4.set_xlabel('Predicci√≥n')
ax4.set_ylabel('Realidad')

# Gr√°fica 5: Variabilidad por Cross-Validation
ax5 = axes[1, 1]
k_vals = list(cv_results.keys())
means = [cv_results[k]['mean'] for k in k_vals]
stds = [cv_results[k]['std'] for k in k_vals]
ax5.errorbar(k_vals, means, yerr=stds, fmt='o-', capsize=5, capthick=2, color='purple')
ax5.set_xlabel('N√∫mero de Vecinos (k)')
ax5.set_ylabel('Accuracy (Cross-Validation)')
ax5.set_title('Variabilidad del Modelo\n(10-Fold Cross-Validation)')
ax5.grid(True, alpha=0.3)

# Gr√°fica 6: Diagn√≥stico Visual
ax6 = axes[1, 2]
# Crear gr√°fica de radar para diagn√≥stico
categories = ['Bias', 'Varianza', 'Ajuste']
values = []

# Convertir diagn√≥sticos a valores num√©ricos (0-1, donde 1 es mejor)
bias_score = 1 - (0.8 if bias_level == "ALTO" else 0.5 if bias_level == "MEDIO" else 0.2)
variance_score = 1 - (0.8 if variance_level == "ALTA" else 0.5 if variance_level == "MEDIA" else 0.2)
fit_score = 0.8 if fit_level == "GOOD FIT" else 0.3

values = [bias_score, variance_score, fit_score]
colors_diag = ['red' if v < 0.4 else 'orange' if v < 0.7 else 'green' for v in values]

bars_diag = ax6.bar(categories, values, color=colors_diag, alpha=0.7)
ax6.set_ylabel('Score (1 = Mejor)')
ax6.set_title('Diagn√≥stico del Modelo\n(Bias/Varianza/Ajuste)')
ax6.set_ylim(0, 1)
for bar, val, cat in zip(bars_diag, values, categories):
    level = bias_level if cat == 'Bias' else variance_level if cat == 'Varianza' else fit_level
    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, 
             level, ha='center', va='bottom', fontweight='bold', fontsize=9)

plt.tight_layout()
plt.savefig('analisis_knn_completo.png', dpi=300, bbox_inches='tight')
print("üìà Gr√°ficas guardadas en 'analisis_knn_completo.png'")

# ======================
# 9. REPORTE FINAL
# ======================

print("\n" + "="*80)
print("üìã REPORTE FINAL DE AN√ÅLISIS")
print("="*80)

print(f"""
üéØ RESULTADOS PRINCIPALES:
‚Ä¢ Mejor k encontrado: {best_k} vecinos
‚Ä¢ Accuracy en Entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)
‚Ä¢ Accuracy en Validaci√≥n: {validation_accuracy:.4f} ({validation_accuracy*100:.2f}%)
‚Ä¢ Accuracy en Prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)

üîç DIAGN√ìSTICOS:
‚Ä¢ BIAS (Sesgo): {bias_level}
  ‚îî‚îÄ‚îÄ {bias_explanation}
  
‚Ä¢ VARIANZA: {variance_level}
  ‚îî‚îÄ‚îÄ {variance_explanation}
  
‚Ä¢ AJUSTE: {fit_level}
  ‚îî‚îÄ‚îÄ {fit_explanation}

üìä M√âTRICAS DE CALIDAD:
‚Ä¢ Gap Entrenamiento-Validaci√≥n: {train_val_gap:.4f} ({train_val_gap*100:.2f}%)
‚Ä¢ Gap Validaci√≥n-Prueba: {val_test_gap:.4f} ({val_test_gap*100:.2f}%)
‚Ä¢ Variabilidad Cross-Validation: {cv_results[best_k]['std']:.4f}

üéñÔ∏è CONCLUSI√ìN GENERAL:
El modelo KNN con k={best_k} muestra un {fit_level.lower()}, con {bias_level.lower()} bias y 
{variance_level.lower()} varianza. {'Es adecuado para producci√≥n.' if fit_level == 'GOOD FIT' else 'Requiere ajustes adicionales.'}
""")

# Guardar resultados en archivo
with open('analisis_resultados.txt', 'w', encoding='utf-8') as f:
    f.write(f"""AN√ÅLISIS COMPLETO DEL MODELO KNN
================================

CONFIGURACI√ìN:
- Dataset: 2016-2024_liga_mx.csv
- Registros: {len(df_clean)}
- Caracter√≠sticas: 3 (goles primer tiempo + temporada)
- Divisi√≥n: 60% Train / 20% Validation / 20% Test

RESULTADOS:
- Mejor k: {best_k}
- Accuracy Entrenamiento: {train_accuracy:.4f}
- Accuracy Validaci√≥n: {validation_accuracy:.4f}
- Accuracy Prueba: {test_accuracy:.4f}

DIAGN√ìSTICOS:
- Bias: {bias_level} - {bias_explanation}
- Varianza: {variance_level} - {variance_explanation}
- Ajuste: {fit_level} - {fit_explanation}

M√âTRICAS:
- Gap Train-Val: {train_val_gap:.4f}
- Gap Val-Test: {val_test_gap:.4f}
- Std CV: {cv_results[best_k]['std']:.4f}
""")

print("\n‚úÖ An√°lisis completado. Archivos generados:")
print("  üìà analisis_knn_completo.png (gr√°ficas)")
print("  üìÑ analisis_resultados.txt (reporte)")
print("\n" + "="*80)